# 摘要理解编码的发展历史

2 hex -> 10 hex -> ascii -> unicode -> utf-8

大致是根据历史的发展：

s1、机器码，不管你，反正电脑能跑就行
s2、机器码好难记啊！那就用 10 进制表示 ascii 码，也就是最初用来表示让美国佬看得懂的代码，对应操作符号还有 abcd 啥的，这样都看的懂互相发了啥
s3、中国佬也想看的懂，日本鬼子也想看的懂，那就整个统一编码吧，本土化
s4、英文一个字节就能表示了啊，unicode 这个傻逼还要难道还要 4 个字节来表示吗？浪费是可耻的，那整个动态的吧，根据需要动态分配字节空间，尽量不造成浪费

为啥会出现 base64？

> 我们知道在计算机中的字节共有 256 个组合，对应就是 ascii 码，而 ascii 码的 128 ～ 255 之间的值是不可见字符。而在网络上交换数据时，比如说从 A 地传到 B 地，往往要经过多个路由设备，由于不同的设备对字符的处理方式有一些不同，这样那些不可见字符就有可能被处理错误，这是不利于传输的。所以就先把数据先做一个 Base64 编码，统统变成可见字符，这样出错的可能性就大降低了。摘自[为什么要使用 base64 编码，有哪些情景需求？](https://www.zhihu.com/question/36306744/answer/71626823)

大概意思是针对传输过程中，某些路由设备会屏蔽不可见的 ascii 码（估计也是标准不统一），导致发送方和接收方的内容不一致，才诞生出 base64 这种编码格式来解决这样的问题

进一步了解 base64 的应用场景，可以看下这个[文章](https://www.birdpython.com/posts/1/59/)

跟 URL 编码的区别是啥？
完全不一样的处理场景。
URL 编码是针对网络请求协议中非 ascii 码的字符，以字符组合的方式来替代，保证请求的准确性。
base64 是针对不可见字节（超出 ascii 范围），以字符（a-z 这些，ascii 范围内）组合的方式组成本文，这样序列化后再转换成字节流在网络中传输到目的地。目的是解决由于不可见字节造成内容缺失的问题。
